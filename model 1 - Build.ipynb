{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Trader Workstation \n",
    "** from Interactive Brokers (testing use port 7497 for paper trading account.) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IB connected to 127.0.0.1:7497 clientId=3>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from ib_insync import *\n",
    "util.startLoop()\n",
    "\n",
    "ib = IB()\n",
    "ib.connect('127.0.0.1', 7497, clientId=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ib.isConnected()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the Stock we wish to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2010, 6, 29, 8, 0)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "contract = Stock('TSLA', 'SMART', 'USD')\n",
    "# shows date of first available historical data (how far back we can model).\n",
    "ib.reqHeadTimeStamp(contract, whatToShow='TRADES', useRTH=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRADES HISTORICAL_VOLATILITY OPTION_IMPLIED_VOLATILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_data = ib.reqHistoricalData(\n",
    "        contract,\n",
    "        endDateTime='',\n",
    "        durationStr='90 D',\n",
    "        barSizeSetting='1 min',\n",
    "        whatToShow='TRADES',\n",
    "        useRTH=True,\n",
    "        formatDate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Option implied volitiilty data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "option_implied_vol = ib.reqHistoricalData(\n",
    "        contract,\n",
    "        endDateTime='',\n",
    "        durationStr='90 D',\n",
    "        barSizeSetting='1 min',\n",
    "        whatToShow='OPTION_IMPLIED_VOLATILITY',\n",
    "        useRTH=True,\n",
    "        formatDate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BarData(date=datetime.datetime(2018, 4, 10, 6, 30), open=0.62367767, high=0.62367767, low=0.60111999, close=0.60111999, average=0.62367767)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option_implied_vol[0]\n",
    "# trade_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to ready data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_prep(trade_data, option_implied_vol):\n",
    "    # convert into dataframes \n",
    "    df_trades = util.df(trade_data)\n",
    "    df_optImpVol = util.df(option_implied_vol)\n",
    "    # remove empty colums (volume, barcount) and rename columns so they dont conflict with Trades\n",
    "    df_optImpVol.drop(columns=['volume', 'barCount'], inplace=True)\n",
    "    # Rename cols\n",
    "    df_optImpVol.rename(index=str, columns={\"open\": \"volOpen\", \"high\":\"volHigh\", \"low\":\"volLow\", \"close\":\"volClose\", \"average\":\"volAverage\"})\n",
    "    # Merge datasets\n",
    "    df_merged = df_trades.merge(df_optImpVol, left_on='date', right_on='date', how='outer')\n",
    "    #  add new columns and normalize data. \n",
    "    #  ROC_min = close_x - open_x / open_x * 100    # Rate of change per minute\n",
    "    df_merged['ROC_min'] = ( df_merged['close_x'] - df_merged['open_x'] ) / ( df_merged['open_x']  ) \n",
    "    #  perMinVol = high_x - low_x / low_x * 100     # intra minute spread volitity\n",
    "    df_merged['perMinVol'] = ( df_merged['high_x'] - df_merged['low_x'] ) / df_merged['low_x'] \n",
    "    # adding 7day rolling mean for price \n",
    "    df_merged['rollMean_7day'] = df_merged['close_x'].rolling(2940).mean()\n",
    "    # drop unwanted columns: open_x, high_x, low_x, average_x, open_y, hight_y, low_y, average_y \n",
    "    df_merged.drop(columns=['date','open_x', 'high_x', 'low_x', 'average_x', 'open_y', 'high_y', 'low_y', 'average_y'], inplace=True)\n",
    "#     # Rename cols\n",
    "#     df_merged.rename(index=str, columns={\"close_x\":\"price_close\", \"close_y\":\"avgMinVol\"})\n",
    "#     df_merged.head(3)\n",
    "\n",
    "    return df_merged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34920, 7)\n",
      "   close_x  volume  barCount   close_y   ROC_min  perMinVol  rollMean_7day\n",
      "0   297.58    1756       538  0.601120 -0.004050   0.007073            NaN\n",
      "1   294.97     930       484  0.601120 -0.007737   0.008515            NaN\n",
      "2   294.09     854       483  0.614582 -0.002747   0.006402            NaN\n",
      "(31970, 7)\n",
      "      close_x  volume  barCount   close_y   ROC_min  perMinVol  rollMean_7day\n",
      "2950   295.83     130        67  0.545797 -0.001957   0.002096     296.880895\n",
      "2951   295.38     118        83  0.545797 -0.001454   0.002712     296.880320\n",
      "2952   295.63     117        64  0.547718  0.000440   0.002237     296.879350\n"
     ]
    }
   ],
   "source": [
    "df = data_prep(trade_data, option_implied_vol)\n",
    "print(df.shape)\n",
    "print(df.head(3))\n",
    "# remove the NaN's from rollMean_7day\n",
    "df = df[2950 : ]\n",
    "print(df.shape)\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled [0.19425869 0.0108019  0.01710282 0.6464882  0.4806246  0.06093334\n",
      " 0.22548771]\n",
      "This is reframed.head     var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.198270   0.011900   0.013806   0.646488   0.470348   0.047099   \n",
      "2   0.194259   0.010802   0.017103   0.646488   0.480625   0.060933   \n",
      "3   0.196487   0.010710   0.013188   0.652902   0.519303   0.050272   \n",
      "4   0.195953   0.004669   0.005976   0.652902   0.506172   0.017493   \n",
      "5   0.198359   0.007598   0.009685   0.648449   0.529668   0.028901   \n",
      "\n",
      "   var7(t-1)   var1(t)  \n",
      "1   0.225495  0.194259  \n",
      "2   0.225488  0.196487  \n",
      "3   0.225475  0.195953  \n",
      "4   0.225461  0.198359  \n",
      "5   0.225449  0.198538  \n",
      "reframed shape (31969, 8)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "# dataset = read_csv('/Users/lorinfields/Downloads/pollution.csv', header=0, index_col=0)\n",
    "dataset = df\n",
    "\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "# encoder = LabelEncoder()\n",
    "# values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# # ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "print('scaled', scaled[1])\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[8,9,10,11,12,13]], axis=1, inplace=True)\n",
    "print('This is reframed.head ', reframed.head())\n",
    "print('reframed shape', reframed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31969, 8)\n",
      "[0.19827032 0.0119004  0.01380589 0.6464882  0.47034776 0.04709882\n",
      " 0.2254951  0.19425869]\n",
      "(25000, 1, 7) (25000,) (6969, 1, 7) (6969,)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_min = 25000\n",
    "print(values.shape)\n",
    "print(values[0])\n",
    "train = values[:n_train_min, :]\n",
    "test = values[n_train_min:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 6969 samples\n",
      "Epoch 1/50\n",
      " - 6s - loss: 0.0074 - val_loss: 0.0417\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.0065 - val_loss: 0.0223\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.0033 - val_loss: 0.0072\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 5/50\n",
      " - 1s - loss: 7.9198e-04 - val_loss: 0.0075\n",
      "Epoch 6/50\n",
      " - 1s - loss: 7.9640e-04 - val_loss: 0.0124\n",
      "Epoch 7/50\n",
      " - 1s - loss: 6.7809e-04 - val_loss: 0.0130\n",
      "Epoch 8/50\n",
      " - 1s - loss: 4.7486e-04 - val_loss: 0.0103\n",
      "Epoch 9/50\n",
      " - 1s - loss: 2.8431e-04 - val_loss: 0.0065\n",
      "Epoch 10/50\n",
      " - 1s - loss: 1.6622e-04 - val_loss: 0.0034\n",
      "Epoch 11/50\n",
      " - 1s - loss: 1.4384e-04 - val_loss: 0.0018\n",
      "Epoch 12/50\n",
      " - 1s - loss: 1.9724e-04 - val_loss: 0.0016\n",
      "Epoch 13/50\n",
      " - 1s - loss: 2.6723e-04 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      " - 1s - loss: 3.0576e-04 - val_loss: 0.0023\n",
      "Epoch 15/50\n",
      " - 1s - loss: 2.9287e-04 - val_loss: 0.0021\n",
      "Epoch 16/50\n",
      " - 1s - loss: 2.3573e-04 - val_loss: 0.0015\n",
      "Epoch 17/50\n",
      " - 1s - loss: 1.5968e-04 - val_loss: 6.2143e-04\n",
      "Epoch 18/50\n",
      " - 1s - loss: 9.4970e-05 - val_loss: 1.5051e-04\n",
      "Epoch 19/50\n",
      " - 1s - loss: 5.8000e-05 - val_loss: 3.4350e-04\n",
      "Epoch 20/50\n",
      " - 1s - loss: 4.2925e-05 - val_loss: 7.6861e-04\n",
      "Epoch 21/50\n",
      " - 1s - loss: 3.6083e-05 - val_loss: 7.1318e-04\n",
      "Epoch 22/50\n",
      " - 1s - loss: 3.1227e-05 - val_loss: 4.3064e-04\n",
      "Epoch 23/50\n",
      " - 1s - loss: 2.9960e-05 - val_loss: 2.5713e-04\n",
      "Epoch 24/50\n",
      " - 1s - loss: 3.1745e-05 - val_loss: 1.9011e-04\n",
      "Epoch 25/50\n",
      " - 1s - loss: 3.4043e-05 - val_loss: 1.6390e-04\n",
      "Epoch 26/50\n",
      " - 1s - loss: 3.5742e-05 - val_loss: 1.4864e-04\n",
      "Epoch 27/50\n",
      " - 1s - loss: 3.6874e-05 - val_loss: 1.3716e-04\n",
      "Epoch 28/50\n",
      " - 2s - loss: 3.7414e-05 - val_loss: 1.2772e-04\n",
      "Epoch 29/50\n",
      " - 1s - loss: 3.7299e-05 - val_loss: 1.1948e-04\n",
      "Epoch 30/50\n",
      " - 1s - loss: 3.6676e-05 - val_loss: 1.1238e-04\n",
      "Epoch 31/50\n",
      " - 1s - loss: 3.5803e-05 - val_loss: 1.0659e-04\n",
      "Epoch 32/50\n",
      " - 1s - loss: 3.4874e-05 - val_loss: 1.0193e-04\n",
      "Epoch 33/50\n",
      " - 1s - loss: 3.3965e-05 - val_loss: 9.8239e-05\n",
      "Epoch 34/50\n",
      " - 1s - loss: 3.3130e-05 - val_loss: 9.5122e-05\n",
      "Epoch 35/50\n",
      " - 1s - loss: 3.2378e-05 - val_loss: 9.2262e-05\n",
      "Epoch 36/50\n",
      " - 1s - loss: 3.1709e-05 - val_loss: 8.9496e-05\n",
      "Epoch 37/50\n",
      " - 1s - loss: 3.1121e-05 - val_loss: 8.6847e-05\n",
      "Epoch 38/50\n",
      " - 1s - loss: 3.0616e-05 - val_loss: 8.4513e-05\n",
      "Epoch 39/50\n",
      " - 1s - loss: 3.0183e-05 - val_loss: 8.2518e-05\n",
      "Epoch 40/50\n",
      " - 1s - loss: 2.9822e-05 - val_loss: 8.1113e-05\n",
      "Epoch 41/50\n",
      " - 1s - loss: 2.9534e-05 - val_loss: 8.0285e-05\n",
      "Epoch 42/50\n",
      " - 1s - loss: 2.9306e-05 - val_loss: 7.9996e-05\n",
      "Epoch 43/50\n",
      " - 1s - loss: 2.9124e-05 - val_loss: 8.0116e-05\n",
      "Epoch 44/50\n",
      " - 1s - loss: 2.8975e-05 - val_loss: 8.0634e-05\n",
      "Epoch 45/50\n",
      " - 1s - loss: 2.8864e-05 - val_loss: 8.1472e-05\n",
      "Epoch 46/50\n",
      " - 1s - loss: 2.8777e-05 - val_loss: 8.2568e-05\n",
      "Epoch 47/50\n",
      " - 1s - loss: 2.8710e-05 - val_loss: 8.3851e-05\n",
      "Epoch 48/50\n",
      " - 1s - loss: 2.8663e-05 - val_loss: 8.5254e-05\n",
      "Epoch 49/50\n",
      " - 1s - loss: 2.8632e-05 - val_loss: 8.6711e-05\n",
      "Epoch 50/50\n",
      " - 1s - loss: 2.8612e-05 - val_loss: 8.8154e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# *** Now we can define and fit our LSTM model.\n",
    "# We will define the LSTM with 50 neurons in the first hidden layer and 1 neuron in the output layer for predicting pollution. The input shape will be 1 time step with 8 features.\n",
    "# We will use the Mean Absolute Error (MAE) loss function and the efficient Adam version of stochastic gradient descent.\n",
    "# The model will be fit for 50 training epochs with a batch size of 72. Remember that the internal state of the LSTM in Keras is reset at the end of each batch, so an internal state that is a function of a number of days may be helpful (try testing this).\n",
    "# Finally, we keep track of both the training and test loss during training by setting the validation_data argument in the fit() function. At the end of the run both the training and test loss are plotted.\n",
    "# ***\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "# model.compile(loss='mae', optimizer='adam')\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.053\n",
      "(6969,)\n",
      "(6969,)\n",
      "296.633\n",
      "296.9\n",
      "6969\n",
      "totalGain 43.700164794921875\n",
      "totalBuys 1716\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print(inv_yhat.shape)\n",
    "print(inv_y.shape)\n",
    "print(inv_yhat[500])\n",
    "print(inv_y[500])\n",
    "runs = len(inv_y)\n",
    "print(runs)\n",
    "# if the model predicts the stock is going up it buys a share and sells the following minute.\n",
    "# if the stock does indeed gain the net is added to total. If it loses the net loss is subtracted \n",
    "# from total.\n",
    "totalGain = 0\n",
    "totalBuys = 0\n",
    "for i in range(runs - 1):\n",
    "    if ((inv_yhat[i + 1] - inv_y[i]) > .3 ):\n",
    "        totalGain += inv_y[i + 1] - inv_y[i]\n",
    "        totalBuys += 1\n",
    "#         print('gain= ', inv_yhat[i + 1] - inv_y[i])\n",
    "#         print('% gain= ', ((inv_yhat[i + 1] - inv_y[i]) / inv_y[i]))\n",
    "              \n",
    "print('totalGain', totalGain)\n",
    "print('totalBuys', totalBuys)\n",
    "print('inv_y[])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
